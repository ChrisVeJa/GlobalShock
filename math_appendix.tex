\documentclass[12pt, a4paper]{article}
\renewcommand{\baselinestretch}{1.15}
\usepackage[left=3cm,right=3cm, top=3cm]{geometry}

\usepackage{enumerate}
\usepackage{amsmath}                                       %
\usepackage{amsthm}                                        %
\usepackage{amssymb}                                       %
\usepackage[english]{babel}  % Caracteres en ESPAÃ‘OL
\usepackage[utf8]{inputenc}
\usepackage{authblk}
\usepackage{graphicx}
\usepackage{fancyhdr}

\pagestyle{fancy}
\fancyhf{}
\fancyhead[CE,CO]{}

\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}


\title{\textbf{Global optimism shocks, heterogeneous effects in small open economies: Methodological appendix}}
\author{Velasquez, C.}
%\affil{Central Reserve Bank of Peru}
\date{}


\begin{document}

\maketitle

\section{Medium Run identification}
In this section as an introduction to the global optimism identification we present the procedure used in Uhlig (2003) to identify anticipated shocks and a modification considering an exogenous block that is relevant to analyse small open economies.
 \subsection{The model}
 To make easier the algebra, we assume a VAR with N variables ( $n^f$ external variables, and $n^d$ domestic variables),an exogenous block. Its reduce form is:
	\begin{equation}
	   \begin{aligned}
	     \left[ \begin{array}{c}  y^{f}_t  \\ y^{d}_t \end{array} \right]
	    =
      	\left[ \begin{array}{cc}  F_{ff} & 0 \\ F_{df} & F_{dd} \end{array} \right]
		\left[ \begin{array}{c}  y^{f}_{t-1}  \\ y^{d}_{t-1}  \end{array} \right]
	 	+
    	\left[ \begin{array}{c}  u^f_{t}  \\ u^d_{t}  \end{array} \right]
	  \end{aligned}
	\end{equation} \\
	The reduced errors, $u^e_{t}$ and $u^d_{t}$ are normally distributed with a variance-covariance matrix $\Sigma$. After applying and orthogonalization by cholesky decomposition:
	\begin{equation}
	   \begin{aligned}
	     \left[ \begin{array}{c}  y^{f}_t  \\ y^{d}_t \end{array} \right]
	    & =
		\left[ \begin{array}{cc}  F_{ff} & 0 \\ F_{df} & F_{dd}\end{array} \right]
		\left[ \begin{array}{c}  y^{f}_{t-1}  \\ y^{d}_{t-1}  \end{array} \right]
	 	+
    	\left[ \begin{array}{cc}  C_{ff} & 0 \\ C_{df} & C_{dd}\end{array} \right]  *\left[ \begin{array}{c}  \epsilon^f_{t}  \\ \epsilon^d_{t}  \end{array} \right]  \\
	   Y_t & = F Y_{t-1} + C E_t
	\end{aligned}
	\end{equation} \\
Both, $\epsilon^e_{t}$ and $\epsilon^d_{t}$ are \textit{orthogonal} errors distributed as a multivariate normal with mean 0 and the identity as variance-covariance. The forecast error will be:
\begin{equation*}
	Y_{t+h}  - E[T_{t+h}|t]& = \sum_{i=0}^h F^{i} C e_{t+h-i} = \sum_{i=0}^h R_{i} e_{t+h-i}
\end{equation*}
The matrix $R_i$ is the reduce-form impulse-response matrix $i$ periods ahead. Then, the forecast variance error is:
\begin{equation}
	 \Omega^{(h)} = \sum_{i=0}^h R_{i} R'_{i}
\end{equation}
The diagonal of $\Omega$ registers the forecast error variance $h-step$ ahead for each variable of the system.
\subsection{Identification of \textit{augmented}-anticipated shock}
Any new identification matrix D will be observationally equivalent to the base model while D satisfies the condition $D'D=I$, implying:
\begin{equation*}
	 \Omega^{(h)} = \sum_{i=0}^h R_{i}D D' R'_{i}
\end{equation*}
On the other hand, we can decompose $\Omega$ into the contribution of each identified shock by the impulse column vector $\gamma_j$
\begin{equation}{\label{eq:n2}}
	 \Omega^{(h)} = \sum_{i=0}^h \sum_{j=1}^{j=n} R_{i}\gamma_j \gamma_j' R'_{i}
\end{equation}
The problem consits in finding the identification vector $\gamma$ which maximizes the contribution of the j- structural shock in the accumulated forecast error variance (S) for an
specific variable $k$ between the periods $[\underline{\tau}, \overline{\tau}]$. To solve it, first we define the portion of S explained by a given structural shock $j$ as:
\begin{equation}
S(\underline{\tau},\overline{\tau}|j) =  \sum_{h = \underline{\tau}}^{\overline{\tau}}\sum_{i=0}^h R_{i}\gamma_j \gamma_j' R'_{i}
\end{equation}
Setting the maximization problem for the variable $k$:
\begin{equation}\label{eq:n1}
\begin{aligned}
& \gamma^* &= \underset{\gamma}{\text{argmax}}
& \left(\sum_{h = \underline{\tau}}^{\overline{\tau}}\sum_{i=0}^h R_{i}\gamma \gamma' R'_{i} \right)_{kk}\\
& \text{s.t.}
&  & \gamma' \gamma = 1 \\
&  & & \gamma(z)  = 0 \quad \forall \ z>n^f
\end{aligned}
\end{equation}
The first condition allows to identify $\gamma$. The second one ensures that only external variables explain the forecast variance of $k$. A way to make easier (\ref{eq:n1}) is defining a matrix $G_{NxN}$ of zeros with 1 in the $kxk$ position, and using the trace operator, then:
\begin{equation*}
\left(\sum_{h = \underline{\tau}}^{\overline{\tau}}\sum_{i=0}^h R_{i}\gamma \gamma' R'_{i} \right)_{kk}  = \sum_{h = \underline{\tau}}^{\overline{\tau}}\sum_{i=0}^h tr(G R_{i}\gamma \gamma' R'_{i} G') = \gamma' \left( \sum_{h =\underline{\tau}}^{\overline{\tau}}\sum_{i=0}^h  (G R_{i})'(G R_{i}) \right) \gamma
\end{equation*}
Defining $R^{(k)}$ as the k-row of matrix $R_i$.
\begin{equation*}
\begin{aligned}
\gamma' \left( \sum_{h =\underline{\tau}}^{\overline{\tau}}\sum_{i=0}^h  (G R_{i})'(G R_{i}) \right) \gamma &= \gamma' \left( \sum_{h =\underline{\tau}}^{\overline{\tau}}\sum_{i=0}^h  R^{'(k)}_i R^{(k)}_i \right) \gamma \\
&= \gamma' \underbrace{\left(\sum_{i=0}^H (\overline{\tau}+1-max(\underline{\tau},i)) R^{'(k)}_iR^{(k)}_i \right)}_{\Lambda} \gamma
\end{aligned}
\end{equation*}
Finally, the system could be re-written as:
\begin{equation*}
\begin{aligned}
& \gamma^* &= \underset{\gamma}{\text{argmax}}  \quad
& \gamma' \Lambda  \gamma \\
& \text{s.t.}
&  & \gamma' \gamma = 1 \\
&  & & \gamma(z)  = 0 \quad \forall \ z>n^f
\end{aligned}
\end{equation*}
The solution of this problem is the eigenvector related to the maximum eigenvalue for $\Lambda^f$ which is a submatrix of $\Lambda$ that includes the first $n^f$ rows and columns. \\
Regarding the second restriction, after expand the last expression for the external variables in a h-step ahead
\begin{equation*}
\begin{aligned}
R^{'(k)}_i\gamma' \gamma R_i^{(k)} &= \left[ \begin{array}{c}  C_{ff}^{'(h)}  \\ 0 \end{array} \right] \left[ \begin{array}{cc}  \gamma'_f & \gamma'_d  \end{array} \right] \left[ \begin{array}{c}  \gamma_f  \\ \gamma_d  \end{array} \right]
\left[ \begin{array}{cc}  C_{ff}^{(h)} &  0 \end{array} \right] \\
&= \left[ \begin{array}{cc} C^{'(h)}_{ff}\gamma'_f \gamma_f C^{(h)}_{ff} + C^{'(h)}_{ff}\gamma'_d \gamma_d C^{(h)}_{dd}  & 0 \\ 0 & 0 \end{array} \right]
\end{aligned}
\end{equation*}
The reduce rank makes us to include $n$ additional restriction over $\gamma$, being natural to assume $\gamma_d$ equal to 0.
\section{Global Shocks identification}
I extend the previous methodology to obtain a vector $\gamma$ which maps structural shocks that explain at maximum the forecastability in a group of variables, - the external ones in this case. \\
Defining $S^{i}(\underline{\tau},\overline{\tau}|j)$ the forecast variance of the i-variable explained by the $j$ structural shock over the period-time $[\underline{\tau}:\overline{\tau}]$ we can modify the original problem into:
\begin{equation*}
\begin{aligned}
& \gamma^* &= \underset{\gamma}{\text{argmax}}  \quad
&  \sum_i^{n^*}\frac{S^{i}(\underline{\tau},\overline{\tau}|\gamma)}{S^{i}(\underline{\tau},\overline{\tau})} \\
& \text{s.t.}
&  & \gamma' \gamma = 1 \\
&  & & \gamma(z)  = 0 \quad \forall \ z>n^f
\end{aligned}
\end{equation*}
It can be seem as recovering the underlying driver of the global economy, hence we call it as the global shock. The restrictions has the same goal as before.
Rewriting the problem:
\begin{equation*}
\sum_i^{n^*}\frac{S^{i}(\underline{\tau},\overline{\tau}|\gamma)}{S^{i}(\underline{\tau},\overline{\tau})}
 =  \sum_i^{n^*}\frac{\gamma' \Lambda^{(i)} \gamma}{S^{i}(\underline{\tau},\overline{\tau})}
 =   \frac{\sum_i^{n^*} \left( \prod_{j=1,j\neq i}^{n^*} S^{i}(\underline{\tau},\overline{\tau})\right) \left( \gamma' \Lambda^{(i)} \gamma \right)}{\prod_i^{n^*} S^{i}(\underline{\tau},\overline{\tau})}
= \gamma' \xi  \gamma
\end{equation*}
Therefore, the problem is:
\begin{equation*}
\begin{aligned}
\gamma^* =  & \quad \underset{\gamma_j}{\text{argmax}}
& & \gamma' \xi \gamma \\
& \text{s.t.}
& & \gamma' \gamma = 1\\
& & & \gamma(z) = 0 \ \forall \ z > n^f
\end{aligned}
\end{equation*}
Finally, $\gamma^*$ is the eigenvector related to the maximum eigenvalue of $\xi$.
\subsection{Identifying a non-fundamental shocks}
In order to identify a non-fundamental shock, which is defined as an innovation that is not related to global movements, I present a novel way to find a second shock. \\
I define $\Lambda^{(i)}$ as the accumulated FEV matrix of an $i$ variable. Then, the system to solve is:
\begin{equation*}
\begin{aligned}
\Psi* =  & \quad \underset{\Psi}{\text{argmax}}
& & \Psi' \Lambda^{(i)} \Psi \\
& \text{s.t.}
& & \Psi' \Psi = 1\\
& & & \Psi'\gamma = 0 \\
& & & \Psi'(z) = 0 \ \forall \ z > n^*
\end{aligned}
\end{equation*}
The new restriction $\Psi' \gamma = 0$ is imposed to ensure that the second identification vector will be orthogonal to the global shock.\\
Lets work with the $n^f$ (since the rest are 0), the second condition implies that:
\begin{align*}
	\begin{bmatrix}
		\psi_1 & \psi_2 & ... &\psi_n
	\end{bmatrix}
	\begin{bmatrix}
		\gamma_1 \\ \gamma_2 \\ \vdots \\ \gamma_n
	\end{bmatrix} = 0 \\
	\psi_1 = -\frac{\sum_{k=i}^{n}\psi_i\gamma_i}{\gamma_1}
\end{align*}
Hence, we can rewrite the vector $\Psi$ as
\begin{equation*}
	\Psi = \psi_2 	\begin{bmatrix}
						-\frac{\gamma_2}{\gamma_1} \\ 1 \\ 0 \\ \vdots \\ 0
					\end{bmatrix}
	+ ... + \psi_n
	\begin{bmatrix}
					-\frac{\gamma_n}{\gamma_1} \\ 0 \\ 0 \\ \vdots \\ 1
				\end{bmatrix}
				\rightarrow
	\begin{bmatrix}\psi_2 & ...&\psi_n\end{bmatrix}
	\begin{bmatrix} \begin{matrix} -\frac{\gamma_2}{\gamma_1}\\ \vdots \\ -\frac{\gamma_n}{\gamma_1}\end{matrix} & I \end{bmatrix} = \varphi'\Gamma'
\end{equation*}
From the first constraint:
\begin{align*}
	\varphi'\Gamma'\Gamma \varphi &= 1 \\
	\varphi' B \varphi &= 1
\end{align*}
From the lagrangian
\begin{equation*}
	\mathcal{L} = \varphi\Gamma'\Lambda^{(i)}\Gamma\varphi + \lambda(1-\varphi B \Psi_{-} ) = \varphi\Lambda_{\Gamma}\varphi + \lambda(1-\varphi' B \varphi )
\end{equation*}
with the FOC:
\begin{equation*}
	\Lambda_{\Gamma}*\varphi = \lambda B \varphi
\end{equation*}
Which is a generalized eigenvalue-eigenvector problem. Therefore, the solution will be the vector associated with the larger generalized eigenvalue.
\end{document}
